name: sync-raw-dataset
on:
    push:
        branches:
            - master
        paths:
            - 'raw/**'

permissions:
    id-token: write
    contents: read

jobs:
    login-to-azure-and-run-azcopy:
        runs-on: ubuntu-latest
        environment: prod-deploy
        defaults:
            run:
                working-directory: raw
        steps:
            - name: Checkout repository
              uses: actions/checkout@v6

            - name: Authenticate to Azure
              uses: azure/login@v2
              with:
                client-id: ${{ secrets.AZURE_CLIENT_ID }}
                tenant-id: ${{ secrets.AZURE_TENANT_ID }}
                subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}

            - name: Check working directory
              run: ls -l

            - name: Get storage account and sync raw dataset
              run: |
                STORAGEACCOUNT=$(az storage account list --query "[?starts_with(name, 'tfuniversityrankings')]" | jq -r ".[0]")
                STORAGE_ACCOUNT_URL=$(echo "$STORAGEACCOUNT" | jq -r ".primaryEndpoints.blob")
                ACCOUNT_NAME=$(echo "$STORAGEACCOUNT" | jq -r ".name")
                RAW_CONTAINER=$(az storage container list --account-name "$ACCOUNT_NAME" --query "[?name=='raw']" 2>/dev/null | jq -r ".[0].name")
                RAW_ENDPOINT_URL=$STORAGE_ACCOUNT_URL$RAW_CONTAINER
                echo "Raw dataset folder storage endpoint: $RAW_ENDPOINT_URL"
                azcopy sync . "$RAW_ENDPOINT_URL" --delete-destination=true --include-pattern "*.csv"
              env:
                AZCOPY_AUTO_LOGIN_TYPE: AZCLI
                AZCOPY_TENANT_ID: ${{ secrets.AZURE_TENANT_ID }}

            - name: Trigger pipeline to ingest data
              run: |
                RESOURCEGROUP=$(az group list --query "[?contains(name,'university-rankings')]" | jq -r ".[0].name")
                DATAFACTORY=$(az datafactory list --resource-group "$RESOURCEGROUP" | jq -r ".[0].name")
                DRIVERPIPELINE=$(az datafactory pipeline list --factory-name "$DATAFACTORY" --resource-group "$RESOURCEGROUP" --query "[?contains(name, 'driver')]" | jq -r ".[0].name")
                az datafactory pipeline create-run --factory-name "$DATAFACTORY" --pipeline-name "$DRIVERPIPELINE" --resource-group "$RESOURCEGROUP"
